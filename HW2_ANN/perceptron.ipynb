{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "80c984d4",
      "metadata": {
        "id": "80c984d4"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "activation functions"
      ],
      "metadata": {
        "id": "eF_TqPdvkYF8"
      },
      "id": "eF_TqPdvkYF8"
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "98b66dba",
      "metadata": {
        "id": "98b66dba"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "trainging the model"
      ],
      "metadata": {
        "id": "KiN9XWj0kbU9"
      },
      "id": "KiN9XWj0kbU9"
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "846200c0",
      "metadata": {
        "id": "846200c0"
      },
      "outputs": [],
      "source": [
        "def train_perceptron(inputs, labels, learning_rate, epochs):\n",
        "    # Initialize random weights and bias\n",
        "    np.random.seed(42)\n",
        "    weights = np.random.rand(len(inputs[0]))\n",
        "    bias = np.random.rand()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(len(inputs)):\n",
        "            # Forward pass\n",
        "            input_vector = inputs[i]\n",
        "            output = sigmoid(np.dot(input_vector, weights) + bias)\n",
        "\n",
        "            # Compute error\n",
        "            error = labels[i] - output\n",
        "\n",
        "            # Update weights and bias using gradient descent\n",
        "            weights += learning_rate * error * sigmoid(output) * input_vector\n",
        "            bias += learning_rate * error * sigmoid(output)\n",
        "\n",
        "\n",
        "    return weights, bias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "31b1155f",
      "metadata": {
        "id": "31b1155f"
      },
      "outputs": [],
      "source": [
        "def predict(input_vector, weights, bias):\n",
        "    return sigmoid(np.dot(input_vector, weights) + bias)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "73d6c95b",
      "metadata": {
        "id": "73d6c95b"
      },
      "outputs": [],
      "source": [
        "# Training data\n",
        "inputs = np.array([[1, 0, 1, 1, 1, 1, 1, 0, 1],\n",
        "                   [1, 1, 1, 1, 0, 1, 1, 0, 1]])\n",
        "\n",
        "# Labels: 1 for 'H', 0 for 'L'\n",
        "labels = np.array([1, 0])\n",
        "\n",
        "# Normalize inputs to values between 0 and 1\n",
        "inputs = inputs / np.max(inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "3d5d436f",
      "metadata": {
        "id": "3d5d436f"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "epochs = 100\n",
        "\n",
        "# Train the perceptron\n",
        "weights, bias = train_perceptron(inputs, labels, learning_rate, epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "7d2e6f5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d2e6f5f",
        "outputId": "9d538f16-298b-439d-96a4-e585606deb32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 0.8524876070260221, Class: H\n"
          ]
        }
      ],
      "source": [
        "# Test the perceptron\n",
        "test_input = np.array([1, 0, 1, 1, 1, 1, 1, 0, 1])  # Should be classified as 'H'\n",
        "normalized_input = test_input / np.max(test_input)\n",
        "\n",
        "prediction = predict(normalized_input, weights, bias)\n",
        "print(f'Prediction: {prediction}, Class: {\"H\" if prediction >= 0.5 else \"L\"}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "3cef8147",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cef8147",
        "outputId": "92ece381-5741-442e-c473-11fa24ab678a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Pattern 1 - Prediction: 0.8525, Class: H\n",
            "Training Pattern 2 - Prediction: 0.1765, Class: L\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(inputs)):\n",
        "    prediction = predict(inputs[i], weights, bias)\n",
        "    print(f'Training Pattern {i + 1} - Prediction: {prediction:.4f}, Class: {\"H\" if prediction >= 0.5 else \"L\"}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "noisy inputs:"
      ],
      "metadata": {
        "id": "H0KphjickP_q"
      },
      "id": "H0KphjickP_q"
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "d67e4cb7",
      "metadata": {
        "id": "d67e4cb7"
      },
      "outputs": [],
      "source": [
        "def add_noise(pattern, num_pixels):\n",
        "    # Randomly flip the values of a limited number of pixels in the pattern\n",
        "    noisy_pattern = pattern.copy()\n",
        "    num_pixels = min(num_pixels, len(pattern))\n",
        "    flip_indices = np.random.choice(len(pattern), num_pixels, replace=False)\n",
        "\n",
        "    if len(noisy_pattern.shape) == 1:\n",
        "        # For 1D array\n",
        "        noisy_pattern[flip_indices] = 1 - noisy_pattern[flip_indices]\n",
        "    else:\n",
        "        # For 2D array (assuming each row is a pattern)\n",
        "        noisy_pattern[:, flip_indices] = 1 - noisy_pattern[:, flip_indices]\n",
        "\n",
        "    return noisy_pattern\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "33d5b916",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "33d5b916",
        "outputId": "1b935c0f-8a24-4d4c-8e28-a07b4c6ed25c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-e6831b5ff60e>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_noisy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_noisy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (10,) and (9,) not aligned: 10 (dim 0) != 9 (dim 0)"
          ]
        }
      ],
      "source": [
        "# Test the model with noisy data\n",
        "L_noisy = np.array([[0, 0.2, 0],[0.3, 0, 1],[1.2, 1, 1]])\n",
        "H_noisy = np.array([[0, 1, 0.2],[0, 0.2, 1],[1.3, 0, 0]])\n",
        "\n",
        "X_noisy = np.vstack((L_noisy.flatten(), H_noisy.flatten()))\n",
        "y_noisy = np.array([0, 1])\n",
        "correct_predictions = 0\n",
        "for i in range(len(X_noise)):\n",
        "    x = np.concatenate((X_noisy[i] , bias))\n",
        "    y_true = y_noisy[i]\n",
        "    y_pred = sigmoid(np.dot(x, weights))\n",
        "\n",
        "    if y_true == y_pred:\n",
        "        correct_predictions += 1\n",
        "    print('predicted output for noisy input: ',y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wr6xrZWr5bO8"
      },
      "id": "Wr6xrZWr5bO8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}